{
  "_comment": "generated by google gemini",
  "text": "This quiz is based on the introduction to modern machine learning frameworks like TensorFlow, PyTorch, and JAX. It covers their core functionalities such as automatic differentiation, GPU computation, the concept of computational graphs, and the role of high-level APIs like Keras.",
  "quiz": [
    {
      "question": "What is the primary function of automatic differentiation (autodiff)?",
      "type": "choice",
      "options": [
        "To automatically compute gradients of functions.",
        "To automatically configure hardware for functions.",
        "To automatically distribute the execution of functions.",
        "To automatically document the purpose of functions."
      ],
      "answer": "To automatically compute gradients of functions.",
      "explanation": "Automatic differentiation is the core mechanism that enables gradient-based optimization in neural networks by computing gradients."
    },
    {
      "question": "Modern ML frameworks are optimized to run tensor computations on specialized hardware like...",
      "type": "blank",
      "answer": "GPUs",
      "explanation": "GPUs (Graphics Processing Units) are highly parallel processors that can significantly accelerate the matrix and vector operations common in deep learning."
    },
    {
      "question": "Keras is best described as a high-level API that uses a ... for computation.",
      "type": "choice",
      "options": [
        "computational backend.",
        "computational frontend.",
        "computational compiler.",
        "computational interpreter."
      ],
      "answer": "computational backend.",
      "explanation": "Keras provides a user-friendly interface that simplifies model building, while relying on a powerful backend like TensorFlow for execution."
    },
    {
      "question": "The conceptual ancestor of modern frameworks like TensorFlow and PyTorch was...",
      "type": "blank",
      "answer": "Theano",
      "explanation": "Theano was a pioneering library that laid the groundwork for many of the core features found in today's frameworks."
    },
    {
      "question": "What is a 'computational graph' in a framework like TensorFlow?",
      "type": "choice",
      "options": [
        "A data structure representing a sequence of operations.",
        "A data structure representing the model's accuracy.",
        "A data structure representing the model's hyperparameters.",
        "A data structure representing a batch of data."
      ],
      "answer": "A data structure representing a sequence of operations.",
      "explanation": "Frameworks often build a graph of computations, which allows them to perform optimizations before executing the code, leading to better performance."
    },
    {
      "question": "PyTorch is well-known for its ... execution model, where operations are run immediately.",
      "type": "blank",
      "answer": "eager",
      "explanation": "Eager execution (or define-by-run) means that operations are executed as they are called, making debugging more intuitive."
    },
    {
      "question": "JAX is a framework that combines a NumPy-like API with automatic differentiation and...",
      "type": "choice",
      "options": [
        "XLA for accelerated linear algebra.",
        "GPU for graphical processing units.",
        "API for application programming interface.",
        "IDE for integrated development environment."
      ],
      "answer": "XLA for accelerated linear algebra.",
      "explanation": "JAX combines a NumPy-like API with autodiff and the XLA compiler to achieve high performance, especially on accelerators."
    },
    {
      "question": "In Keras, a 'layer' represents a specific data...",
      "type": "blank",
      "answer": "transformation",
      "explanation": "Each layer in a neural network performs a specific data transformation, such as a dense connection or a convolution."
    },
    {
      "question": "TensorFlow's graph mode is particularly useful for production...",
      "type": "choice",
      "options": [
        "deployment.",
        "development.",
        "debugging.",
        "documentation."
      ],
      "answer": "deployment.",
      "explanation": "Graph mode creates a static, portable graph that is optimized for efficient deployment in environments without a Python interpreter."
    },
    {
      "question": "The `fit()` method in Keras abstracts away the entire...",
      "type": "blank",
      "answer": "training loop",
      "explanation": "The `fit()` method handles the complex process of iterating over data, computing loss, performing backpropagation, and updating weights."
    },
    {
      "question": "A key advantage of a high-level API like Keras is that it enables faster...",
      "type": "choice",
      "options": [
        "model prototyping.",
        "data preprocessing.",
        "model deployment.",
        "hardware configuration."
      ],
      "answer": "model prototyping.",
      "explanation": "High-level APIs are designed to improve developer productivity by providing simple building blocks, which reduces boilerplate code."
    },
    {
      "question": "The fundamental data structure that flows through all modern deep learning frameworks is the...",
      "type": "blank",
      "answer": "tensor",
      "explanation": "Tensors are the multi-dimensional arrays that serve as the basic data containers in deep learning."
    },
    {
      "question": "Distributed computation is a key feature for handling large-scale models and...",
      "type": "choice",
      "options": [
        "large-scale datasets.",
        "large-scale APIs.",
        "large-scale teams.",
        "large-scale deployments."
      ],
      "answer": "large-scale datasets.",
      "explanation": "Distributed training is essential for tackling problems with massive datasets and models in a reasonable amount of time."
    },
    {
      "question": "A model's `compile()` step in Keras is where you specify the optimizer and...",
      "type": "blank",
      "answer": "loss function",
      "explanation": "The compile step configures the model for training by defining how it will be optimized and how its performance will be measured."
    },
    {
      "question": "PyTorch is often described as having a more 'Pythonic' feel due to its...",
      "type": "choice",
      "options": [
        "imperative programming style.",
        "declarative programming style.",
        "functional programming style.",
        "procedural programming style."
      ],
      "answer": "imperative programming style.",
      "explanation": "PyTorch's eager, imperative style integrates seamlessly with Python, allowing for standard control flow and debugging."
    },
    {
      "question": "In Keras, a layer's weights are typically created when it is first...",
      "type": "blank",
      "answer": "called",
      "explanation": "Keras layers perform 'lazy' initialization, creating their weights only when they know the shape of the input tensor."
    },
    {
      "question": "The TensorFlow ecosystem includes tools for data loading, model deployment, and...",
      "type": "choice",
      "options": [
        "browser-based machine learning.",
        "database-driven machine learning.",
        "cloud-agnostic machine learning.",
        "hardware-accelerated machine learning."
      ],
      "answer": "browser-based machine learning.",
      "explanation": "Tools like TensorFlow.js are part of the vast ecosystem that supports the entire machine learning lifecycle."
    },
    {
      "question": "Function transformations like `grad` and `jit` are characteristic features of...",
      "type": "blank",
      "answer": "JAX",
      "explanation": "JAX is built around the concept of composing function transformations to create powerful, high-performance code."
    },
    {
      "question": "When the same model code can run on a CPU, GPU, or TPU, the framework is described as...",
      "type": "choice",
      "options": [
        "hardware-agnostic.",
        "hardware-dependent.",
        "hardware-optimized.",
        "hardware-specific."
      ],
      "answer": "hardware-agnostic.",
      "explanation": "This abstraction allows developers to focus on the model's logic, while the framework handles the hardware-specific optimizations."
    },
    {
      "question": "A `Sequential` model in Keras is a simple linear stack of...",
      "type": "blank",
      "answer": "layers",
      "explanation": "The Sequential API is a straightforward way to build models where the data flows from one layer to the next in order."
    },
    {
      "question": "TensorFlow 2.x adopted eager execution as its default model, making it more...",
      "type": "choice",
      "options": [
        "interactive and intuitive.",
        "static and optimized.",
        "compiled and portable.",
        "abstract and complex."
      ],
      "answer": "interactive and intuitive.",
      "explanation": "This was a major shift from TensorFlow 1.x and made the framework more user-friendly, similar to PyTorch."
    },
    {
      "question": "Using a trained model to make predictions on new data is known as...",
      "type": "blank",
      "answer": "inference",
      "explanation": "Inference is the process of putting a trained model into a production environment where it can make predictions."
    },
    {
      "question": "What is the primary benefit of XLA (Accelerated Linear Algebra)?",
      "type": "choice",
      "options": [
        "It is a compiler that fuses operations.",
        "It is an API that simplifies operations.",
        "It is a library that defines operations.",
        "It is a tool that visualizes operations."
      ],
      "answer": "It is a compiler that fuses operations.",
      "explanation": "XLA acts as an optimizing backend that can significantly improve the performance of tensor computations by fusing them together."
    },
    {
      "question": "The Keras Functional API is more flexible than `Sequential` because it allows for models with...",
      "type": "blank",
      "answer": "multiple inputs",
      "explanation": "The functional API allows for creating complex models with multiple inputs, multiple outputs, and shared layers."
    },
    {
      "question": "The open-source nature of ML frameworks fosters a large community, leading to rapid...",
      "type": "choice",
      "options": [
        "innovation and support.",
        "competition and fragmentation.",
        "standardization and regulation.",
        "monetization and licensing."
      ],
      "answer": "innovation and support.",
      "explanation": "The collaborative, open-source model is a key driver of the rapid progress seen in the field of deep learning."
    },
    {
      "question": "The loss function calculates the discrepancy between the model's prediction and the...",
      "type": "blank",
      "answer": "true label",
      "explanation": "The goal of training is to minimize this discrepancy, making the model's predictions as close to the ground truth as possible."
    },
    {
      "question": "JAX is fundamentally a library for transforming numerical functions, not a full-fledged...",
      "type": "choice",
      "options": [
        "deep learning platform.",
        "deep learning language.",
        "deep learning compiler.",
        "deep learning interface."
      ],
      "answer": "deep learning platform.",
      "explanation": "While powerful for research, JAX is more focused and less of an all-in-one platform compared to the extensive ecosystems of TensorFlow and PyTorch."
    },
    {
      "question": "The component that implements the backpropagation algorithm by updating weights is the...",
      "type": "blank",
      "answer": "optimizer",
      "explanation": "The optimizer uses the gradients computed by the autodiff engine to update the model's weights in a way that reduces the loss."
    },
    {
      "question": "When defining a custom layer, you must implement a 'call' method that specifies the layer's...",
      "type": "choice",
      "options": [
        "forward pass computation.",
        "backward pass computation.",
        "weight initialization scheme.",
        "memory allocation strategy."
      ],
      "answer": "forward pass computation.",
      "explanation": "The 'call' method defines how the layer transforms its input tensors into output tensors."
    },
    {
      "question": "The `tf.function` decorator in TensorFlow converts eager-style Python code into a high-performance...",
      "type": "blank",
      "answer": "graph",
      "explanation": "This decorator captures the Python code and builds a static computational graph, combining the ease of eager execution with the performance of graph mode."
    },
    {
        "question": "The primary role of an 'optimizer' in the training process is to...",
        "type": "choice",
        "options": [
            "update the model's weights.",
            "define the model's architecture.",
            "load the training data.",
            "calculate the model's loss."
        ],
        "answer": "update the model's weights.",
        "explanation": "The optimizer implements an algorithm (like SGD or Adam) to update the model's weights based on the computed gradients to minimize the loss."
    },
    {
        "question": "A framework's 'backend' refers to the low-level library that executes the...",
        "type": "blank",
        "answer": "tensor operations",
        "explanation": "The backend is the computational engine (e.g., TensorFlow) that a high-level API like Keras uses to perform the actual math."
    },
    {
        "question": "Which of these is NOT one of the three key features shared by modern ML frameworks?",
        "type": "choice",
        "options": [
            "Built-in automated hyperparameter tuning.",
            "A way to compute gradients for functions.",
            "A way to run computations on GPUs.",
            "A way to distribute computation."
        ],
        "answer": "Built-in automated hyperparameter tuning.",
        "explanation": "While hyperparameter tuning is part of the ML ecosystem, it's generally a higher-level task, not a fundamental feature of the core framework itself."
    },
    {
        "question": "The `summary()` method of a Keras model provides an overview of its layers and...",
        "type": "blank",
        "answer": "parameter counts",
        "explanation": "This is a useful utility for quickly inspecting a model's architecture and complexity."
    },
    {
        "question": "PyTorch's imperative style means that operations are executed...",
        "type": "choice",
        "options": [
            "sequentially as they appear in code.",
            "after the entire graph is compiled.",
            "in a parallel, non-deterministic way.",
            "only when a session is explicitly run."
        ],
        "answer": "sequentially as they appear in code.",
        "explanation": "This 'define-by-run' approach contrasts with the 'define-and-run' style of static graph frameworks."
    },
    {
        "question": "Keras acts as an 'interface', not a standalone framework, because it requires a...",
        "type": "blank",
        "answer": "backend engine",
        "explanation": "Keras provides the user-friendly API, but it relies on a backend like TensorFlow to handle the heavy computational lifting."
    },
    {
        "question": "PyTorch is based on the Torch library, which provides the underlying...",
        "type": "choice",
        "options": [
            "tensor computation capabilities.",
            "model deployment capabilities.",
            "data visualization capabilities.",
            "automated debugging capabilities."
        ],
        "answer": "tensor computation capabilities.",
        "explanation": "PyTorch is a Python wrapper and extension of the original Torch library, which was written in Lua."
    },
    {
        "question": "A model's `predict()` method is used for the process of...",
        "type": "blank",
        "answer": "inference",
        "explanation": "Inference is the process of using a trained model to make predictions on new, unseen data."
    },
    {
        "question": "TensorFlow's 'gradient tape' is used to record operations for...",
        "type": "choice",
        "options": [
            "automatic differentiation.",
            "performance profiling.",
            "model serialization.",
            "visual debugging."
        ],
        "answer": "automatic differentiation.",
        "explanation": "The GradientTape is the mechanism that enables autodiff in TensorFlow's dynamic, eager execution environment."
    },
    {
        "question": "The core design philosophy of Keras is to enable fast...",
        "type": "blank",
        "answer": "experimentation",
        "explanation": "By simplifying the process of building and training models, Keras allows users to iterate on their ideas much more quickly."
    },
    {
        "question": "What is the primary difference between TensorFlow's graph mode and eager mode?",
        "type": "choice",
        "options": [
            "Graph mode is declarative, eager mode is imperative.",
            "Graph mode is imperative, eager mode is declarative.",
            "Graph mode is for CPUs, eager mode is for GPUs.",
            "Graph mode is for training, eager mode is for inference."
        ],
        "answer": "Graph mode is declarative, eager mode is imperative.",
        "explanation": "In declarative (graph) mode, you define the graph first and then execute it. In imperative (eager) mode, you execute operations on the fly."
    }
  ]
}
